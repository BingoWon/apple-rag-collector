import { AppleAPIClient } from "./AppleAPIClient.js";
import { ContentProcessor } from "./ContentProcessor.js";
import { Chunker } from "./Chunker.js";
import { createEmbeddings } from "./EmbeddingProvider.js";
import { PostgreSQLManager } from "./PostgreSQLManager.js";
import { type DatabaseRecord, type BatchConfig } from "./types/index.js";
import { Logger } from "./utils/logger.js";

interface BatchResult {
  successRecords: DatabaseRecord[];
  failureRecords: DatabaseRecord[];
  deleteIds: string[];
  extractedUrls: Set<string>;
}

interface ContentComparisonResult {
  record: DatabaseRecord;
  collectResult: any;
  hasChanged: boolean;
  newRawJson?: string;
  error?: string;
}

class AppleDocCollector {
  private readonly apiClient: AppleAPIClient;
  private readonly contentProcessor: ContentProcessor;
  private readonly chunker: Chunker;
  private readonly dbManager: PostgreSQLManager;

  private readonly config: BatchConfig;

  constructor(
    dbManager: PostgreSQLManager,
    _logger: Logger,
    config: BatchConfig
  ) {
    this.dbManager = dbManager;
    this.config = config;
    this.apiClient = new AppleAPIClient();
    this.contentProcessor = new ContentProcessor();
    this.chunker = new Chunker(config);
  }

  async execute(): Promise<boolean> {
    const records = await this.dbManager.getBatchRecords(this.config.batchSize);

    if (records.length === 0) {
      return false;
    }

    const result = await this.processBatch(records);
    await this.dbManager.batchProcessRecords(
      result.successRecords,
      result.failureRecords,
      result.deleteIds
    );

    if (result.extractedUrls.size > 0) {
      await this.dbManager.batchInsertUrls([...result.extractedUrls]);
    }

    return true;
  }

  private async processBatch(records: DatabaseRecord[]): Promise<BatchResult> {
    const urls = records.map((r) => r.url);

    // Stage 1: Batch Collecting
    const collectResults = await this.apiClient.fetchDocuments(urls);

    // Stage 2: Intelligent Content Comparison
    const comparisonResults = this.compareContentChanges(
      records,
      collectResults
    );

    // Separate changed and unchanged records
    const changedResults = comparisonResults.filter((r) => r.hasChanged);
    const unchangedResults = comparisonResults.filter(
      (r) => !r.hasChanged && !r.error
    );

    // Log intelligent comparison results
    if (unchangedResults.length > 0) {
      console.log(
        `ğŸ”„ Content unchanged: ${unchangedResults.length} URLs (skipping processing)`
      );
    }
    if (changedResults.length > 0) {
      console.log(
        `ğŸ“ Content changed: ${changedResults.length} URLs (full processing)`
      );
    }

    // Stage 3: Process Only Changed Content
    const processResults =
      changedResults.length > 0
        ? await this.contentProcessor.processDocuments(
            changedResults.map((r) => r.collectResult)
          )
        : [];

    // Stage 4: Chunk Only Changed Content
    const chunkResults =
      processResults.length > 0
        ? this.chunker.chunkTexts(
            processResults
              .filter((r) => r.data)
              .map((r) => ({
                url: r.url,
                title: r.data!.title,
                content: r.data!.content,
              }))
          )
        : [];

    // Stage 5: Embed Only Changed Content
    const allChunks = chunkResults.flatMap((r) =>
      r.data ? r.data.map((chunk) => ({ url: r.url, chunk })) : []
    );

    // Parse JSON chunks and combine title + content for embedding
    const embeddingTexts = allChunks.map((c) => {
      try {
        const parsed = JSON.parse(c.chunk);
        // Combine title and content for optimal semantic representation
        return parsed.title
          ? `${parsed.title}\n\n${parsed.content}`
          : parsed.content;
      } catch (error) {
        console.warn("Failed to parse chunk JSON, using raw chunk:", error);
        return c.chunk;
      }
    });

    const embeddings =
      embeddingTexts.length > 0 ? await createEmbeddings(embeddingTexts) : [];

    // Stage 6: Batch Storage for Changed Content
    if (allChunks.length > 0) {
      const chunksWithEmbeddings = allChunks.map((item, index) => ({
        url: item.url,
        content: item.chunk,
        embedding: embeddings[index] || [],
      }));
      await this.dbManager.insertChunks(chunksWithEmbeddings);
    }

    // Stage 7: Lightweight Update for Unchanged Content
    if (unchangedResults.length > 0) {
      await this.dbManager.batchUpdateCollectCountOnly(
        unchangedResults.map((r) => ({
          id: r.record.id,
          collect_count: r.record.collect_count + 1,
        }))
      );
    }

    return this.buildBatchResult(comparisonResults, processResults);
  }

  /**
   * æ™ºèƒ½å†…å®¹æ¯”è¾ƒï¼šæ¯”è¾ƒæ–°æ—§ raw json åˆ¤æ–­å†…å®¹æ˜¯å¦å˜åŒ–
   */
  private compareContentChanges(
    records: DatabaseRecord[],
    collectResults: any[]
  ): ContentComparisonResult[] {
    return records.map((record, index) => {
      const collectResult = collectResults[index];

      if (!collectResult.data) {
        return {
          record,
          collectResult,
          hasChanged: false,
          error: collectResult.error,
        };
      }

      const newRawJson = JSON.stringify(collectResult.data);
      const oldRawJson = record.raw_json;

      // æ·±åº¦å†…å®¹æ¯”è¾ƒ
      const hasChanged = this.isContentChanged(oldRawJson, newRawJson);

      return {
        record,
        collectResult,
        hasChanged,
        newRawJson,
      };
    });
  }

  /**
   * åˆ¤æ–­å†…å®¹æ˜¯å¦çœŸæ­£å‘ç”Ÿå˜åŒ–
   */
  private isContentChanged(
    oldRawJson: string | null,
    newRawJson: string
  ): boolean {
    if (!oldRawJson) return true; // é¦–æ¬¡æ”¶é›†ï¼Œè®¤ä¸ºæœ‰å˜åŒ–

    try {
      const oldData = JSON.parse(oldRawJson);
      const newData = JSON.parse(newRawJson);

      // æ¯”è¾ƒå…³é”®å†…å®¹å­—æ®µï¼Œå¿½ç•¥å¯èƒ½çš„æ—¶é—´æˆ³ç­‰å…ƒæ•°æ®å˜åŒ–
      return (
        !this.deepEqual(
          oldData.primaryContentSections,
          newData.primaryContentSections
        ) ||
        !this.deepEqual(oldData.metadata, newData.metadata) ||
        !this.deepEqual(oldData.abstract, newData.abstract)
      );
    } catch {
      return true; // JSONè§£æå¤±è´¥æ—¶è®¤ä¸ºæœ‰å˜åŒ–
    }
  }

  /**
   * æ·±åº¦æ¯”è¾ƒä¸¤ä¸ªå¯¹è±¡æ˜¯å¦ç›¸ç­‰
   */
  private deepEqual(obj1: any, obj2: any): boolean {
    if (obj1 === obj2) return true;
    if (obj1 == null || obj2 == null) return obj1 === obj2;
    if (typeof obj1 !== typeof obj2) return false;

    if (Array.isArray(obj1)) {
      if (!Array.isArray(obj2) || obj1.length !== obj2.length) return false;
      return obj1.every((item, index) => this.deepEqual(item, obj2[index]));
    }

    if (typeof obj1 === "object") {
      const keys1 = Object.keys(obj1);
      const keys2 = Object.keys(obj2);
      if (keys1.length !== keys2.length) return false;
      return keys1.every((key) => this.deepEqual(obj1[key], obj2[key]));
    }

    return false;
  }

  private buildBatchResult(
    comparisonResults: ContentComparisonResult[],
    processResults: any[]
  ): BatchResult {
    const successRecords: DatabaseRecord[] = [];
    const failureRecords: DatabaseRecord[] = [];
    const deleteIds: string[] = [];
    const extractedUrls = new Set<string>();

    let processIndex = 0; // ç”¨äºè·Ÿè¸ª processResults çš„ç´¢å¼•

    for (const comparison of comparisonResults) {
      const { record, collectResult, hasChanged, error } = comparison;

      if (collectResult?.error?.includes("PERMANENT_ERROR:")) {
        deleteIds.push(record.id);
      } else if (hasChanged && collectResult?.data) {
        // åªæœ‰å†…å®¹å˜åŒ–çš„è®°å½•æ‰æœ‰å¯¹åº”çš„ processResult
        const processResult = processResults[processIndex++];

        if (processResult?.data) {
          const updatedRecord: DatabaseRecord = {
            id: record.id,
            url: record.url,
            raw_json: comparison.newRawJson!,
            title: processResult.data.title,
            content: processResult.data.content,
            collect_count: record.collect_count + 1,
            created_at: record.created_at,
            updated_at: new Date(),
          };
          successRecords.push(updatedRecord);

          processResult.data.extractedUrls.forEach((url: string) =>
            extractedUrls.add(url)
          );
        } else {
          const errorMessage = processResult?.error || "Processing failed";
          const failureRecord: DatabaseRecord = {
            id: record.id,
            url: record.url,
            raw_json: null,
            title: null,
            content: `ERROR: ${errorMessage}`,
            collect_count: record.collect_count + 1,
            created_at: record.created_at,
            updated_at: new Date(),
          };
          failureRecords.push(failureRecord);
        }
      } else if (error) {
        // æ”¶é›†å¤±è´¥çš„è®°å½•
        const failureRecord: DatabaseRecord = {
          id: record.id,
          url: record.url,
          raw_json: null,
          title: null,
          content: `ERROR: ${error}`,
          collect_count: record.collect_count + 1,
          created_at: record.created_at,
          updated_at: new Date(),
        };
        failureRecords.push(failureRecord);
      }
      // æ³¨æ„ï¼šå†…å®¹æœªå˜åŒ–çš„è®°å½•å·²ç»åœ¨ processBatch ä¸­é€šè¿‡ batchUpdateCollectCountOnly å¤„ç†
    }

    return { successRecords, failureRecords, deleteIds, extractedUrls };
  }
}

export { AppleDocCollector };
